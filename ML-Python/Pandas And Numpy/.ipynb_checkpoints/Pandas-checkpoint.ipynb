{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1764849",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "    You and your team are analysts at a mobile phone company. Your manager asks you to analyze the market trends of             different mobile phone models to understand their performance based on various features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553aa764",
   "metadata": {},
   "source": [
    "#### Reading CSV Files\n",
    "    What's the first thing we should do when we receive a dataset?🤔🤔\n",
    "    The first step is to read the CSV file and load it into a DataFrame to inspect the data. Let's read the file and take a     look at the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e924a21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Rating', 'Spec_score', 'No_of_sim', 'Ram', 'Battery',\n",
       "       'Display', 'Camera', 'External_Memory', 'Android_version', 'Price',\n",
       "       'company', 'Inbuilt_memory', 'fast_charging', 'Screen_resolution',\n",
       "       'Processor', 'Processor_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading the CSV file\n",
    "file_path = 'mobile_data_analysis.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()\n",
    "# Display the all columns of the dataset\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21978fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b8443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the all columns of the dataset\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec8e198",
   "metadata": {},
   "source": [
    "    Our dataset contains various columns like 'Name', 'Rating', 'Spec_score', 'No_of_sim', 'Ram', 'Battery', 'Display',         'Camera', 'External_Memory', 'Android_version', 'Price', 'company', 'Inbuilt_memory', 'fast_charging',                     'Screen_resolution', 'Processor',and 'Processor_name'. Each row represents a different mobile phone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50561b0e",
   "metadata": {},
   "source": [
    "#### Loading Python Data Objects\n",
    "    You know, there's a common misconception😦 that data always comes in csv files. But in reality, data can be stored in       various formats, and that's why we have different functions to read them. It's not just about csv – we can handle           excel files, SQL databases, JSON files, and more. The flexibility to read data from multiple sources is really             important in data analysis🥳"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30acede4",
   "metadata": {},
   "source": [
    "    A dataset can be loaded from various data sources using relevant Pandas constructs (functions) as mentioned below:\n",
    "    CSV file - read_csv() function\n",
    "    JSON file - read_json() function\n",
    "    Excel file - read_excel() function\n",
    "    Database table - read_sql() function\n",
    "    All the above functions return a dataframe object and most of these functions have a parameter called 'chunksize'.\n",
    "    e.g. to load a csv data file (mobile phone price prediction.csv) you can use the above code\n",
    "    data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa1fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading with specific columns\n",
    "data_selected_columns = pd.read_csv(file_path, usecols=['Battery', 'Ram', 'Price'])\n",
    "print(\"\\nReading Specific Columns:\\n\", data_selected_columns.head())\n",
    "\n",
    "# Reading with index column\n",
    "data_with_index = pd.read_csv(file_path, index_col='Name')\n",
    "print(\"\\nReading with Index Column:\\n\", data_with_index.head())\n",
    "\n",
    "# Reading with missing values handling\n",
    "data_missing_values = pd.read_csv(file_path, na_values=['NA', 'n/a', ''])\n",
    "print(\"\\nReading with Missing Values Handling:\\n\", data_missing_values.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f931401",
   "metadata": {},
   "source": [
    "#### Understanding the Data🤓\n",
    "    You look at the data and notice columns like 'Name', 'Rating', 'Spec_score', 'Ram', 'Battery', and many others.\n",
    "    Question: How can we understand the structure and types of data we're dealing with?\n",
    "    We can use methods like info() and describe() to get a better understanding of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c787abad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Displaying information about the DataFrame\n",
    "print(data.info())\n",
    "\n",
    "# Descriptive statistics of numerical columns\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30040510",
   "metadata": {},
   "source": [
    "#### Performing Arithmetic Operations - Crunching Numbers\n",
    "    Our next adventure involves performing arithmetic operations. Suppose we want to understand how doubling the price         impacts our dataset. Let’s create a new column for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fafc974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column with doubled Price\n",
    "data['Double_Price'] = data['Price'] * 2\n",
    "\n",
    "# Display the first few rows to see the new column\n",
    "print(data[['Price', 'Double_Price']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e121d898",
   "metadata": {},
   "source": [
    "    Here, we multiply the 'Price' column by 2 and store it in a new column 'Double_Price'. This simple operation opens the    door to more complex analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542cb5d4",
   "metadata": {},
   "source": [
    "    Can we do other arithmetic operations as well?\"🫤\n",
    "\n",
    "    Absolutely!😊 We can add, subtract, multiply, or divide columns. Let's create a column showing the sum of 'Ram' and           'Battery'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10524c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column with the sum of Ram and Battery\n",
    "data['Ram_Battery_Sum'] = data['Ram'] + data['Battery']\n",
    "\n",
    "# Display the first few rows to see the new column\n",
    "print(data[['Ram', 'Battery', 'Ram_Battery_Sum']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b87705",
   "metadata": {},
   "source": [
    "#### Focusing the Lens - Selecting Data\n",
    "       To find valuable insights, we often need to focus on specific parts of our data. For example, let’s select only the        Name', 'Price', and 'Ram' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b977d05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting specific columns\n",
    "selected_columns = data[['Name', 'Price', 'Ram']]\n",
    "\n",
    "# Display the selected columns\n",
    "print(selected_columns.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b11a6a2",
   "metadata": {},
   "source": [
    "     This is cool!😁 How about selecting rows based on multiple conditions\n",
    "     \n",
    "     This step helps us concentrate on the most relevant data for our analysis. Next, we’ll narrow down our rows to high-        priced phones\n",
    "     \n",
    "     Let’s select phones with 'Price' greater than 20000 and 'Rating' greater than 4 .\"\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967c274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting rows based on multiple conditions\n",
    "high_price_high_rating_phones = data[(data['Price'] > 200) & (data['Rating'] > 4.0)]\n",
    "\n",
    "# Display the selected rows\n",
    "high_price_high_rating_phones.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e491b1",
   "metadata": {},
   "source": [
    "#### Rounding Numbers - Making Data Neat\n",
    "    Clean data is crucial for clear insights. Sometimes, this means rounding numbers to make them more readable. Let’s         round the 'Price' column to the nearest integer.\n",
    "    We can round numbers using the round function. Let's round the 'Price' column to the nearest integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ebd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding the Price column\n",
    "data['Rounded_Price'] = data['Price'].round()\n",
    "\n",
    "# Display the first few rows to see the rounded values\n",
    "print(data[['Price', 'Rounded_Price']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743a81c9",
   "metadata": {},
   "source": [
    "    Rounding the 'Price' column makes our data cleaner and easier to interpret. We can also round other columns to specific     decimal places as needed\n",
    "    \n",
    "    This rounds the 'Price' column to the nearest integer and stores it in a new column 'Rounded_Price'. We can also round     to a specific number of decimal places. For instance, rounding the 'Rating' to one decimal place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2979512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding the Rating column to one decimal place\n",
    "data['Rounded_Rating'] = data['Rating'].round(1)\n",
    "\n",
    "# Display the first few rows to see the rounded values\n",
    "print(data[['Rating', 'Rounded_Rating']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b4ca9b",
   "metadata": {},
   "source": [
    "#### Data Aggregation - Summarizing Data\n",
    "    To gain quick insights, we can summarize our data through aggregation. For instance, let’s calculate the average price     of phones grouped by their company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating data: Calculating the mean Price by company\n",
    "mean_price_by_company = data.groupby('company')['Price'].mean()\n",
    "\n",
    "# Display the aggregated data\n",
    "print(mean_price_by_company)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f30f5",
   "metadata": {},
   "source": [
    "    Grouping by 'company' and calculating the mean 'Price' gives us an overview of how prices vary across different brands.\n",
    "    Exciting !!! Now Let's check which companies phones has the highest rating phones ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddaf7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating data: Calculating Which \n",
    "average_ratings = data.groupby('company')['Rating'].mean().sort_values(ascending=False)\n",
    "\n",
    "# Display the aggregated data\n",
    "average_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85636bad",
   "metadata": {},
   "source": [
    "#### Cleaning Data - Data Munging Techniques\n",
    "    Data isn't always perfect. It often contains missing values or duplicates that need to be addressed. Let’s start by         identifying missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4edea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945f5f21",
   "metadata": {},
   "source": [
    "    We see the count of missing values for each column. Now, let’s fill missing values in 'Android_version' with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623fe7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values in Battery with the mean\n",
    "data['Android_version'].fillna(data['Android_version'].mean(), inplace=True)\n",
    "\n",
    "# Display the first few rows to see changes\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70e837b",
   "metadata": {},
   "source": [
    "    We can also remove duplicate rows to clean our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4a018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates\n",
    "data_no_duplicates = data.drop_duplicates()\n",
    "\n",
    "# Display the first few rows to see changes\n",
    "print(data_no_duplicates.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8840f1d1",
   "metadata": {},
   "source": [
    "####  Saving Our Progress - A Wise Move😌\n",
    "    As we navigate through our analysis, it’s crucial to save our progress. This way, we can pick up right where we left       off. Let’s save our DataFrame to both a CSV file and a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976ab6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to a CSV file\n",
    "data.to_csv('saved_mobile_phone_data.csv', index=False)\n",
    "print(\"Data saved to CSV file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7e46fd",
   "metadata": {},
   "source": [
    "#### Visualizing Data - Bringing Insights to Life\n",
    "    Visualization is a powerful tool to understand data trends and patterns. Let’s plot some graphs to visualize our           findings. First, we need to import the necessary library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f7eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the distribution of phone prices\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(data['Price'], bins=30, edgecolor='k', alpha=0.7)\n",
    "plt.title('Distribution of Phone Prices')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e659c0",
   "metadata": {},
   "source": [
    "    This histogram shows the distribution of phone prices, helping us understand the range and frequency of different price     points.🧐🧐\n",
    "\n",
    "    Next, let’s plot the average price by company using a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7431001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting average price by company\n",
    "mean_price_by_company.plot(kind='bar', figsize=(12, 8), color='skyblue')\n",
    "plt.title('Average Price by Company')\n",
    "plt.xlabel('Company')\n",
    "plt.ylabel('Average Price')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6060301",
   "metadata": {},
   "source": [
    "#### Conclusion: Insights and Learnings\n",
    "\n",
    "    Through this journey, we’ve explored various techniques to read, clean, manipulate, and visualize data using pandas.       We’ve seen how to perform arithmetic operations, select and filter data, handle missing values, aggregate data, merge       datasets, and visualize trends.🤗\n",
    "\n",
    "    Each step has brought us closer to understanding our mobile phone dataset, enabling us to extract meaningful insights       and make informed decisions. This story-driven approach not only teaches us the technical skills but also emphasizes       the importance of clear, clean, and insightful data analysis.🫡"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
